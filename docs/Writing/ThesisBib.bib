
@unknown{BloemP:2018,
	author = {Bloem, Peter and de Rooij, Steven},
	year = {2018},
	month = {10},
	pages = {},
	title = {A tutorial on MDL hypothesis testing for graph analysis}
}


@article{ChristianB:2009,
	title={Linked Data - The Story So Far},
	author={Christian Bizer and Tom Heath and Tim Berners-Lee},
	journal={Int. J. Semantic Web Inf. Syst.},
	year={2009},
	volume={5},
	pages={1-22}
}
@inproceedings{DBpedia,
	author = {Auer, S\"{o}ren and Bizer, Christian and Kobilarov, Georgi and Lehmann, Jens and Cyganiak, Richard and Ives, Zachary},
	title = {DBpedia: A Nucleus for a Web of Open Data},
	booktitle = {Proceedings of the 6th International The Semantic Web and 2Nd Asian Conference on Asian Semantic Web Conference},
	series = {ISWC'07/ASWC'07},
	year = {2007},
	isbn = {3-540-76297-3, 978-3-540-76297-3},
	location = {Busan, Korea},
	pages = {722--735},
	numpages = {14},
	url = {http://dl.acm.org/citation.cfm?id=1785162.1785216},
	acmid = {1785216},
	publisher = {Springer-Verlag},
	address = {Berlin, Heidelberg},
} 

@article{Debattista:2018,
	author = {Debattista, Jeremy and Lange, Christoph and Auer, S\"oren and Cortis, Dominic},
	year = {2018},
	month = {09},
	pages = {859-901},
	title = {Evaluating the Quality of the LOD Cloud: An Empirical Investigation},
	volume = {9},
	journal = {Semantic Web},
	doi = {10.3233/SW-180306}
}

@inproceedings{Eiter:2010,
	author = {Eiter, Thomas and Fink, Michael and Sch\"{u}ller, Peter and Weinzierl, Antonius},
	title = {Finding Explanations of Inconsistency in Multi-context Systems},
	booktitle = {Proceedings of the Twelfth International Conference on Principles of Knowledge Representation and Reasoning},
	series = {KR'10},
	year = {2010},
	isbn = {1-57735-451-6, 978-1-5773-545-12},
	location = {Toronto, Ontario, Canada},
	pages = {329--339},
	numpages = {11},
	url = {http://dl.acm.org/citation.cfm?id=3031748.3031791},
	acmid = {3031791},
	publisher = {AAAI Press},
} 
@inproceedings{Freebase,
	author = {Bollacker, Kurt and Evans, Colin and Paritosh, Praveen and Sturge, Tim and Taylor, Jamie},
	title = {Freebase: A Collaboratively Created Graph Database for Structuring Human Knowledge},
	booktitle = {Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data},
	series = {SIGMOD '08},
	year = {2008},
	isbn = {978-1-60558-102-6},
	location = {Vancouver, Canada},
	pages = {1247--1250},
	numpages = {4},
	url = {http://doi.acm.org/10.1145/1376616.1376746},
	doi = {10.1145/1376616.1376746},
	acmid = {1376746},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {collaborative systems, semantic network, tuple store},
} 
@article{FMPGPA:13,
	author = {Javier D. Fernández and Miguel A. Martínez-Prieto and Claudio Gutiérrez and Axel Polleres and Mario Arias},
	title = {Binary RDF Representation for Publication and Exchange (HDT)},
	url = {http://www.websemanticsjournal.org/index.php/ps/article/view/328},
	journal={Web Semantics: Science, Services and Agents on the World Wide Web},
	volume={19},
	pages={22–41},
	year={2013},
	publisher={Elsevier}
}
@book{Gabbay:1994,
	editor = {Gabbay, Dov M. and Hogger, C. J. and Robinson, J. A.},
	title = {Handbook of Logic in Artificial Intelligence and Logic Programming (Vol. 3): Nonmonotonic Reasoning and Uncertain Reasoning},
	year = {1994},
	isbn = {0-19-853747-6},
	publisher = {Oxford University Press, Inc.},
	address = {New York, NY, USA},
} 
@article{HeikoP:2016,
	author = {Paulheim, Heiko},
	year = {2016},
	month = {12},
	pages = {489-508},
	title = {Knowledge graph refinement: A survey of approaches and evaluation methods},
	volume = {8},
	journal = {Semantic Web},
	doi = {10.3233/SW-160218}
}
@inproceedings{Horridge:2009,
	title={Explaining Inconsistencies in OWL Ontologies},
	author={Matthew Horridge and Bijan Parsia and Ulrike Sattler},
	booktitle={SUM},
	year={2009}
}
@article{Horridge:2011,
	author = {Horridge, Matthew and Bechhofer, Sean},
	title = {The OWL API: A Java API for OWL Ontologies},
	journal = {Semant. web},
	issue_date = {January 2011},
	volume = {2},
	number = {1},
	month = jan,
	year = {2011},
	issn = {1570-0844},
	pages = {11--21},
	numpages = {11},
	url = {http://dl.acm.org/citation.cfm?id=2019470.2019471},
	acmid = {2019471},
	publisher = {IOS Press},
	address = {Amsterdam, The Netherlands, The Netherlands},
	keywords = {API, Java, OWL, application development, reasoning},
} 

@article{JavierD:2013,
	author = {Javier D. Fernández and Miguel A. Martínez-Prieto and Claudio Gutiérrez and Axel Polleres and Mario Arias},
	title = {Binary RDF Representation for Publication and Exchange (HDT)},
	journal = {Web Semantics: Science, Services and Agents on the World Wide Web},
	volume = {19},
	number = {0},
	year = {2013},
	publisher = {Elsevier},
	keywords = {RDF, Binary formats, Data compaction and compression, RDF metrics},
	abstract = {The current Web of Data is producing increasingly large RDF datasets. Massive publication efforts of RDF data driven by initiatives like the Linked Open Data movement, and the need to exchange large datasets has unveiled the drawbacks of traditional RDF representations, inspired and designed by a document-centric and human-readableWeb. Among the main problems are high levels of verbosity/redundancy and weak machine-processable capabilities in thedescription of these datasets. This scenario calls for efficient formats for publication and exchange.This article presents a binary RDF representation addressing these issues. Based on a set ofmetrics that characterizes the skewed structure of real-world RDF data, we develop a proposal of an RDF representation thatmodularly partitions and efficiently represents three components of RDF datasets: Header information, a Dictionary, and the actual Triples structure (thus called HDT). Our experimental evaluation shows that datasets in HDT format can be compacted by more than fifteen times as compared to current naive representations, improving both parsing and processing while keeping a consistent publication scheme. Specific compression techniques over HDT further improve these compression rates and prove to outperform existing compression solutions for efficient RDF exchange.},
	issn = {1570-8268},
	url = {http://www.websemanticsjournal.org/index.php/ps/article/view/328}
}

@inproceedings{JavierD:2017,
	title={LOD-a-lot - A Queryable Dump of the LOD Cloud},
	author={Javier D. Fern{\'a}ndez and Wouter Beek and Miguel A. Mart{\'i}nez-Prieto and Mario Arias},
	booktitle={International Semantic Web Conference},
	year={2017}
}
@article{Jin:2011,
	author = {Jin, Long and Chen, Yang and Hui, Pan and Ding, Cong and Wang, Tianyi and Vasilakos, Athanasios and Deng, Beixing and Li, Xing},
	year = {2011},
	month = {07},
	pages = {},
	title = {Albatross sampling: robust and effective hybrid vertex sampling for social graphs},
	doi = {10.1145/2000172.2000178}
}
@inproceedings{Kaminski:2015,
	author = {Kaminski, Tobias and Knorr, Matthias and Leite, Jo\~{a}o},
	title = {Efficient Paraconsistent Reasoning with Ontologies and Rules},
	booktitle = {Proceedings of the 24th International Conference on Artificial Intelligence},
	series = {IJCAI'15},
	year = {2015},
	isbn = {978-1-57735-738-4},
	location = {Buenos Aires, Argentina},
	pages = {3098--3105},
	numpages = {8},
	url = {http://dl.acm.org/citation.cfm?id=2832581.2832681},
	acmid = {2832681},
	publisher = {AAAI Press},
} 
@article{Kurant:2011,
	author    = {Maciej Kurant and
	Athina Markopoulou and
	Patrick Thiran},
	title     = {Towards Unbiased {BFS} Sampling},
	journal   = {CoRR},
	volume    = {abs/1102.4599},
	year      = {2011},
	url       = {http://arxiv.org/abs/1102.4599},
	archivePrefix = {arXiv},
	eprint    = {1102.4599},
	timestamp = {Mon, 13 Aug 2018 16:47:14 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1102-4599},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}
@ARTICLE{LCordella2004,
	author={L. P. Cordella and P. Foggia and C. Sansone and M. Vento},
	journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
	title={A (sub)graph isomorphism algorithm for matching large graphs},
	year={2004},
	volume={26},
	number={10},
	pages={1367-1372},
	keywords={computational complexity;pattern matching;graph theory;graph isomorphism algorithm;graphs matching;subgraph isomorphism;spatial complexity;technical drawings;Pattern recognition;Pattern matching;Pattern analysis;Application software;NP-complete problem;Performance analysis;Algorithm design and analysis;Testing;Performance evaluation;Relational databases;Index Terms- Graph-subgraph isomorphism;large graphs;attributed relational graphs.;Algorithms;Artificial Intelligence;Cluster Analysis;Computer Graphics;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Information Storage and Retrieval;Numerical Analysis, Computer-Assisted;Pattern Recognition, Automated;Reproducibility of Results;Sensitivity and Specificity;Signal Processing, Computer-Assisted;Subtraction Technique},
	doi={10.1109/TPAMI.2004.75},
	ISSN={0162-8828},
	month={Oct},}

@inproceedings{Leskovec:2006,
	author = {Leskovec, Jure and Faloutsos, Christos},
	title = {Sampling from Large Graphs},
	booktitle = {Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	series = {KDD '06},
	year = {2006},
	isbn = {1-59593-339-5},
	location = {Philadelphia, PA, USA},
	pages = {631--636},
	numpages = {6},
	url = {http://doi.acm.org/10.1145/1150402.1150479},
	doi = {10.1145/1150402.1150479},
	acmid = {1150479},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {graph mining, graph sampling, scaling laws},
} 

@InProceedings{MatthewH:2009,
	author="Horridge, Matthew
	and Parsia, Bijan
	and Sattler, Ulrike",
	editor="Godo, Llu{\'i}s
	and Pugliese, Andrea",
	title="Explaining Inconsistencies in OWL Ontologies",
	booktitle="Scalable Uncertainty Management",
	year="2009",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="124--137",
	abstract="Justifications play a central role as the basis for explaining entailments in OWL ontologies. While techniques for computing justifications for entailments in consistent ontologies are theoretically and practically well-understood, little is known about the practicalities of computing justifications for inconsistent ontologies. This is despite the fact that justifications are important for repairing inconsistent ontologies, and can be used as a basis for paraconsistent reasoning. This paper presents algorithms, optimisations, and experiments in this area. Surprisingly, it turns out that justifications for inconsistent ontologies are more ``difficult'' to compute and are often more ``numerous'' than justifications for entailments in consistent ontologies: whereas it is always possible to compute some justifications, it is often not possible to compute all justifications for real world inconsistent ontologies.",
	isbn="978-3-642-04388-8"
}
@article{McAreavey:2014,
	author = {McAreavey, Kevin and Liu, Weiru and Miller, Paul},
	year = {2014},
	month = {11},
	pages = {},
	title = {Computational approaches to finding and measuring inconsistency in arbitrary knowledge bases},
	volume = {55},
	journal = {International Journal of Approximate Reasoning},
	doi = {10.1016/j.ijar.2014.06.003}
}
@article{MichaelF:2017,
	author = {F\"arber, Michael and Bartscherer, Frederic and Menne, Carsten and Rettinger, Achim},
	year = {2017},
	month = {03},
	pages = {1-53},
	title = {Linked data quality of DBpedia, Freebase, OpenCyc, Wikidata, and YAGO},
	volume = {9},
	journal = {Semantic Web},
	doi = {10.3233/SW-170275}
}
@inproceedings{MPAF:12,
	author = {Miguel A. Martínez-Prieto and Mario Arias and Javier D. Fernández},
	title = {Exchange and Consumption of Huge RDF Data},
	year = {2012},
	booktitle={The Semantic Web: Research and Applications},
	pages = {437-452},
	publisher={Springer}
}
@article{Noori:2015,
	author = {Noori, Azad and Moradi, Farzad},
	year = {2015},
	month = {12},
	pages = {230},
	title = {Simulation and Comparison of Efficency in Pathfinding algorithms in Games},
	volume = {37},
	journal = {Ciência e Natura},
	doi = {10.5902/2179460X20778}
}
@online{Openllet:2019,
	author = {Galigater},
	title = {Openllet},
	date = {10 march 2019},
	url = {https://github.com/Galigator/openllet},
}

@online{OWLPrimer:2012,
	author={"P. Hitzler and M. Kr\"otzsch and B. Parsia and P. Patel-Schneider and S. Rudolph"},
	title={"OWL 2 Web Ontology Language Primer (Second Edition)"},
	date={"11-12-2012"},
	note= {"\url{https://www.w3.org/TR/owl-primer/}"},
	organization={"W3C Working Group"}
}
@article{Pellet:2007,
	author = {Sirin, Evren and Parsia, Bijan and Cuenca Grau, Bernardo and Kalyanpur, Aditya and Katz, Yarden},
	year = {2007},
	month = {01},
	pages = {},
	title = {Pellet: A Practical OWL-DL Reasoner},
	journal = {SSRN Electronic Journal},
	doi = {10.2139/ssrn.3199351}
}
@online{rdfPrimer:2014,
	author = {"G. Schreiber, Y. Raimond"},
	title = {"RDF primer 1.1"},
	date = {"24-06-2014"},
	organization = {"W3C Working Group"},
	note = {"\url{https://www.w3.org/TR/rdf11-primer/}"}
}

@InProceedings{Rietveld:2014,
	author={"Rietveld, Laurens
	and Hoekstra, Rinke
	and Schlobach, Stefan
	and Gu{\'e}ret, Christophe",
	editor="Mika, Peter
	and Tudorache, Tania
	and Bernstein, Abraham
	and Welty, Chris
	and Knoblock, Craig
	and Vrande{\v{c}}i{\'{c}}, Denny
	and Groth, Paul
	and Noy, Natasha
	and Janowicz, Krzysztof
	and Goble, Carole"},
	title={"Structural Properties as Proxy for Semantic Relevance in RDF Graph Sampling"},
	booktitle={"The Semantic Web -- ISWC 2014"},
	year={"2014"},
	publisher={"Springer International Publishing"},
	address={"Cham"},
	pages={"81--96"},
	abstract={"The Linked Data cloud has grown to become the largest knowledge base ever constructed. Its size is now turning into a major bottleneck for many applications. In order to facilitate access to this structured information, this paper proposes an automatic sampling method targeted at maximizing answer coverage for applications using SPARQL querying. The approach presented in this paper is novel: no similar RDF sampling approach exist. Additionally, the concept of creating a sample aimed at maximizing SPARQL answer coverage, is unique. We empirically show that the relevance of triples for sampling (a semantic notion) is influenced by the topology of the graph (purely structural), and can be determined without prior knowledge of the queries. Experiments show a significantly higher recall of topology based sampling methods over random and naive baseline approaches (e.g. up to 90{\%} for Open-BioMed at a sample size of 6{\%})."},
	isbn={"978-3-319-11915-1"}
}


@online{SPARQLPrimer:2013,
	author = "S. Harris, A. Seaborne",
	title = "SPARQL 1.1 Query Language",
	date = "21-03-2013",
	organization = "W3C Working Group",
	note = "\url{https://www.w3.org/TR/sparql11-query/}",
}

@book{toulmin:1956, place={Cambridge}, edition={2}, title={The Uses of Argument}, DOI={10.1017/CBO9780511840005}, publisher={Cambridge University Press}, author={Toulmin, Stephen E.}, year={2003}}

@inproceedings{Topper:2012,
	author = {T\"{o}pper, Gerald and Knuth, Magnus and Sack, Harald},
	title = {DBpedia Ontology Enrichment for Inconsistency Detection},
	booktitle = {Proceedings of the 8th International Conference on Semantic Systems},
	series = {I-SEMANTICS '12},
	year = {2012},
	isbn = {978-1-4503-1112-0},
	location = {Graz, Austria},
	pages = {33--40},
	numpages = {8},
	url = {http://doi.acm.org/10.1145/2362499.2362505},
	doi = {10.1145/2362499.2362505},
	acmid = {2362505},
	publisher = {ACM},
	address = {New York, NY, USA},
	keywords = {DBpedia, data cleansing, linked data, ontology enrichment},
} 
@InProceedings{WouterB:2014,
	author={"Beek, Wouter
	and Rietveld, Laurens
	and Bazoobandi, Hamid R.
	and Wielemaker, Jan
	and Schlobach, Stefan"},
	editor={"Mika, Peter
	and Tudorache, Tania
	and Bernstein, Abraham
	and Welty, Chris
	and Knoblock, Craig
	and Vrande{\v{c}}i{\'{c}}, Denny
	and Groth, Paul
	and Noy, Natasha
	and Janowicz, Krzysztof
	and Goble, Carole"},
	title={"LOD Laundromat: A Uniform Way of Publishing Other People's Dirty Data"},
	booktitle={"The Semantic Web -- ISWC 2014"},
	year={"2014"},
	publisher={"Springer International Publishing"},
	address={"Cham"},
	pages={"213--228"},
	abstract={"It is widely accepted that proper data publishing is difficult. The majority of Linked Open Data (LOD) does not meet even a core set of data publishing guidelines. Moreover, datasets that are clean at creation, can get stains over time. As a result, the LOD cloud now contains a high level of dirty data that is difficult for humans to clean and for machines to process."},
	isbn={"978-3-319-11964-9"}
}


@article{YAGO,
	author = {Suchanek, Fabian M. and Kasneci, Gjergji and Weikum, Gerhard},
	title = {YAGO: A Large Ontology from Wikipedia and WordNet},
	journal = {Web Semant.},
	issue_date = {September, 2008},
	volume = {6},
	number = {3},
	month = sep,
	year = {2008},
	issn = {1570-8268},
	pages = {203--217},
	numpages = {15},
	url = {http://dx.doi.org/10.1016/j.websem.2008.06.001},
	doi = {10.1016/j.websem.2008.06.001},
	acmid = {1412998},
	publisher = {Elsevier Science Publishers B. V.},
	address = {Amsterdam, The Netherlands, The Netherlands},
	keywords = {Information extraction, Knowledge representation, Ontologies},
}

@article{YAGO2:2013,
	author = {Hoffart, Johannes and M. Suchanek, Fabian and Berberich, Klaus and Weikum, Gerhard},
	year = {2013},
	month = {01},
	pages = {28-61},
	title = {YAGO2: A Spatially and Temporally Enhanced Knowledge Base from Wikipedia},
	volume = {194},
	journal = {Artificial Intelligence},
	doi = {10.1016/j.artint.2012.06.001}
}





@article{Zhi:2015,
	author = {Zhi, Hui-lai},
	year = {2015},
	month = {08},
	pages = {1-7},
	title = {A Max-Term Counting Based Knowledge Inconsistency Checking Strategy and Inconsistency Measure Calculation of Fuzzy Knowledge Based Systems},
	volume = {2015},
	journal = {Mathematical Problems in Engineering},
	doi = {10.1155/2015/134950}
}
















 







